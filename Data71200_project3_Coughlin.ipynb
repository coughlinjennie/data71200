{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCksaFprlCalszV/MmwTyA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coughlinjennie/data71200/blob/main/Data71200_project3_Coughlin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Load data and libraries"
      ],
      "metadata": {
        "id": "SKhD3HUdDlIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng1BICXdDb3_"
      },
      "outputs": [],
      "source": [
        "#Load libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import requests\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install -U scikit-learn==1.4\n",
        "\n",
        "import six\n",
        "import joblib\n",
        "import sys\n",
        "sys.modules['sklearn.externals.six'] = six\n",
        "sys.modules['sklearn.externals.joblib'] = joblib\n",
        "!pip install mglearn\n",
        "import mglearn\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "\n",
        "#Import the data, sourced from Kaggle and stored in my GitHub\n",
        "url = \"https://raw.githubusercontent.com/coughlinjennie/data71200/main/projects/nyhousing.csv\" # Make sure the url is the raw version of the file on GitHub\n",
        "download = requests.get(url).content\n",
        "#Load the data\n",
        "\n",
        "housing_master = pd.read_csv(io.StringIO(download.decode('utf-8')))"
      ],
      "metadata": {
        "id": "gy6_zf6JDtvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all rows where column 'TYPE' has certain values\n",
        "indexType = housing_master[ (housing_master['TYPE'] == \"For sale\") | (housing_master['TYPE'] == \"Contingent\") | (housing_master['TYPE'] == \"Land for sale\") | (housing_master['TYPE'] == \"Foreclosure\") | (housing_master['TYPE'] == \"Pending\") | (housing_master['TYPE'] == \"Coming Soon\") | (housing_master['TYPE'] == \"Mobile house for sale\") ].index\n",
        "housing_master.drop(indexType , inplace=True)\n",
        "\n",
        "#Set the labels on TYPE\n",
        "\n",
        "housing_label = housing_master[\"TYPE\"]\n",
        "\n",
        "#Set the data\n",
        "housing = housing_master.drop(\"TYPE\", axis=1)\n",
        "\n",
        "#Divide the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing_train, housing_test, housing_label_train, housing_label_test = train_test_split(housing, housing_label, test_size=0.3, stratify=housing_label, random_state=42)\n",
        "\n",
        "# Create a list of redundant column names to drop from the training data only\n",
        "to_drop = [\"LONGITUDE\", \"LATITUDE\", \"ADDRESS\", \"ADMINISTRATIVE_AREA_LEVEL_2\", \"LOCALITY\", \"SUBLOCALITY\", \"FORMATTED_ADDRESS\", \"MAIN_ADDRESS\", \"STATE\", \"STREET_NAME\",\"LONG_NAME\",\"BROKERTITLE\"]\n",
        "\n",
        "# Drop those columns from the dataset\n",
        "housing_subset = housing_train.drop(to_drop, axis = 1)\n",
        "h_test_subset = housing_test.drop(to_drop, axis = 1)\n",
        "\n",
        "#Drop all properties that sold for more than $1B from training data only\n",
        "\n",
        "housing_clean = housing_subset[housing_subset['PRICE'] <= 100000000]\n",
        "label_train_clean = housing_label_train[housing_subset['PRICE'] <= 100000000]\n"
      ],
      "metadata": {
        "id": "lbC6gz-nY_gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale features as needed\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "housing_scaled = scaler.fit_transform(housing_clean)\n"
      ],
      "metadata": {
        "id": "OrPc2yEZDur_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: PCA for feature selection"
      ],
      "metadata": {
        "id": "py7o2DRsDvIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep the components that explain 95% of the variance in the data\n",
        "pca = PCA(n_components=0.95)\n",
        "# fit PCA model to data\n",
        "housing_pca = pca.fit_transform(housing_scaled)\n"
      ],
      "metadata": {
        "id": "hl_4Y6p6Dzps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the Decision Tree model from Project 2 again with PCA data\n",
        "model3 = DecisionTreeClassifier(random_state=0).fit(housing_pca, label_train_clean)\n",
        "\n",
        "print(\"Accuracy on training set: {:.2f}\".format(model3.score(housing_pca, label_train_clean)))\n"
      ],
      "metadata": {
        "id": "HEFhsvWFD22A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate model performance vs. original\n",
        "\n",
        "model = DecisionTreeClassifier(random_state=0).fit(housing_scaled, label_train_clean)\n",
        "print(\"Accuracy on training set: {:.2f}\".format(model.score(housing_scaled, label_train_clean)))\n",
        "\n"
      ],
      "metadata": {
        "id": "UF1C3gglD3Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Apply Clustering to Data and Visualize Output"
      ],
      "metadata": {
        "id": "6lPvTl8CEQu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##K-means clustering"
      ],
      "metadata": {
        "id": "Y0oULTaKElbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the model with PCA applied"
      ],
      "metadata": {
        "id": "6JHmV64nEjiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the ARI"
      ],
      "metadata": {
        "id": "NwGVNc9cEzEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the Silhouette Configuration"
      ],
      "metadata": {
        "id": "bx-nVg7FE2VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the model without PCA applied"
      ],
      "metadata": {
        "id": "lVLXtgqTEuy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the ARI"
      ],
      "metadata": {
        "id": "jV2avwquE_kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the Silhouette Configuration"
      ],
      "metadata": {
        "id": "sizot1NfE_LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Agglomerate/hierarchical"
      ],
      "metadata": {
        "id": "6SCRcY68FDum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the model with PCA applied"
      ],
      "metadata": {
        "id": "H078SbsXFNMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Le-Jg7EFRE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uU8pqcPsFQ3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the model without PCA applied"
      ],
      "metadata": {
        "id": "ayrBf1qxFSwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DBSCAN"
      ],
      "metadata": {
        "id": "WCsj2LP_FIos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the model with PCA applied"
      ],
      "metadata": {
        "id": "6JyKPp5PFMkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xl3sxkx9FRhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DyxRcaOFSD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the model without PCA applied"
      ],
      "metadata": {
        "id": "-KGYSkWYFU3q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}